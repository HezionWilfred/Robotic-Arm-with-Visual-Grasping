# Robotic Arm with Visual Grasping

[![ROS2](https://img.shields.io/badge/ROS2-Humble-blue)](https://docs.ros.org/en/humble/)
[![Python](https://img.shields.io/badge/Python-3.8+-green)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

> An intelligent robotic arm system capable of autonomous object detection, localization, and grasping using computer vision and deep learning techniques.

## ğŸ¯ Project Overview

This project develops a robotic manipulation system that combines computer vision with robotic control to achieve autonomous grasping of household objects. The system uses an Intel RealSense depth camera for 3D scene understanding and implements real-time object detection, pose estimation, and motion planning for reliable object manipulation.

### Key Features

- **ğŸ¤– Autonomous Operation**: Complete pipeline from object detection to grasping execution
- **ğŸ‘ï¸ Computer Vision**: YOLOv8-based object detection with 6DOF pose estimation  
- **ğŸ“Š Real-time Performance**: <3 second end-to-end latency with â‰¥10 FPS processing
- **ğŸ›¡ï¸ Safety Systems**: Emergency stop, collision avoidance, and speed limiting
- **ğŸ“ˆ High Accuracy**: â‰¥80% grasp success rate with â‰¤2cm positioning accuracy

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RGB-D Camera  â”‚    â”‚  Object Detectionâ”‚    â”‚  Pose Estimationâ”‚
â”‚  (RealSense)    â”‚â”€â”€â”€â–¶â”‚     (YOLOv8)     â”‚â”€â”€â”€â–¶â”‚     (6DOF)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Arm Control    â”‚â—€â”€â”€â”€â”‚  Motion Planning â”‚â—€â”€â”€â”€â”‚  Grasp Planning â”‚
â”‚   (ROS2 Driver)  â”‚    â”‚    (MoveIt!)     â”‚    â”‚   (Synthesis)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Hardware Components

| Component | Model | Purpose | Cost (â‚¹) |
|-----------|-------|---------|----------|
| RGB-D Camera | Intel RealSense D435 | 3D scene reconstruction | 18,000 |
| Robotic Arm | 6-DOF Educational Arm | Object manipulation | 45,000 |
| Gripper | 2-finger Adaptive | Object grasping | 8,000 |
| Computer | NVIDIA Jetson Xavier NX | AI inference & control | 25,000 |
| **Total** | | | **â‚¹96,000** |

## ğŸ’» Software Stack

### Core Technologies
- **ROS 2 Humble** - Robot Operating System framework
- **YOLOv8** - Real-time object detection
- **MoveIt!** - Motion planning and kinematics
- **OpenCV** - Computer vision processing
- **Open3D** - 3D point cloud processing

### Dependencies
```bash
# ROS 2 packages
sudo apt install -y \
  ros-humble-moveit \
  ros-humble-realsense2-camera \
  ros-humble-vision-msgs \
  ros-humble-rviz2 \
  ros-humble-cv-bridge \
  ros-humble-image-transport

# Python packages  
torch torchvision
ultralytics
opencv-python
open3d
pyrealsense2
```

## ğŸ“‹ Target Objects & Performance

### Supported Objects
- **Bottle** (cylindrical, 5-15cm height)
- **Mug** (cylindrical with handle, various sizes)  
- **Box** (rectangular, rigid materials)

### Performance Targets
| Metric | Target | Current |
|--------|--------|---------|
| Grasp Success Rate | â‰¥80% | TBD |
| End-to-End Latency | â‰¤3 seconds | TBD |
| Detection FPS | â‰¥10 FPS | TBD |
| Position Accuracy | â‰¤2cm error | TBD |

## ğŸš€ Quick Start

### Prerequisites
- Ubuntu 20.04 with ROS 2 Humble
- CUDA-capable GPU (GTX 1060+ or Jetson Xavier NX)
- Intel RealSense D435 camera
- Compatible 6-DOF robotic arm

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/your-username/robotic-arm-visual-grasping.git
cd robotic-arm-visual-grasping
```

2. **Install dependencies**
```bash
# Install ROS dependencies
rosdep install --from-paths src --ignore-src -r -y

# Install Python requirements
pip install -r requirements.txt
```

3. **Build the workspace**
```bash
catkin_make
source devel/setup.bash
```

4. **Run calibration**
```bash
ros2 launch robot_grasping calibrate_camera.launch
```

### Basic Usage

1. **Start the complete system**
```bash
ros2 launch robot_grasping full_system.launch
```

2. **Run a grasping demo**
```bash
ros2 service call /grasp_object "object_name: 'bottle'"
```

3. **Monitor system status**
```bash
ros2 topic echo /system_status
```

## ğŸ“Š Development Progress

### Phase 1: Hardware Integration âœ…
- [x] Camera and arm communication setup
- [x] ROS2 node architecture implementation
- [x] Basic safety systems integration

### Phase 2: Perception Module ğŸ”„
- [x] YOLOv8 model training and optimization
- [x] 6DOF pose estimation implementation
- [ ] Real-time performance optimization

### Phase 3: Planning & Control ğŸ“…
- [ ] Grasp synthesis algorithm development
- [ ] MoveIt! motion planning integration
- [ ] Collision avoidance implementation

### Phase 4: System Integration ğŸ“…
- [ ] End-to-end testing and validation
- [ ] Performance benchmarking
- [ ] Safety system validation

## ğŸ”¬ Research & Innovation

### Novel Contributions
- **Efficient Real-time Pipeline**: Optimized for low-latency operation on edge hardware
- **Robust Grasp Planning**: Adaptive grasp synthesis considering object geometry
- **Safety-first Design**: Comprehensive safety monitoring and emergency response

### Future Enhancements
- Multi-object scene manipulation
- Dynamic object tracking and grasping
- Tactile feedback integration
- Mobile platform integration

## ğŸ“ˆ Testing & Validation

### Test Scenarios
1. **Single Object Grasping**: Individual objects in controlled conditions
2. **Multi-object Scenes**: Object selection in cluttered environments  
3. **Lighting Variations**: Performance under different illumination
4. **Error Recovery**: System response to failed grasp attempts

### Success Metrics
- Quantitative performance against KPI targets
- Qualitative assessment of system robustness
- Safety compliance validation
- User experience evaluation

## ğŸ‘¥ Team

- **Hezion Wilfred** (URK23CS7006) - Team Leader, System Integration
- **Jinto Joseph** (URK24CS1210) - Computer Vision & ML
- **Basil Shaji** - Project Mentor & Guide

## ğŸ“š Documentation

- **Requirement Analysis** â€“ Defines the project goals, hardware/software needs, dataset strategy, and evaluation metrics.  
  [ğŸ“– Read Full Document](https://docs.google.com/document/d/e/2PACX-1vTWHIKLwAYOayBMhqomi4HyCJyX6zqyl8QpjLR8-sovp_6rvmV_aca9dDCFIUuPn8mCMpcf9qqHAqK1/pub)  
- [System Design](https://docs.google.com/document/d/e/2PACX-1vQWGvF9tzwzcWJiz9-WvZGufjkWumws61UdmAHC1DF8FfClAnKO5x-FtkmKsAKcBcEzFPeYtYDkS2Y_/pub) â€“ Technical architecture overview  
- [API Reference](docs/api.md) â€“ ROS2 topics, services, and messages  
- [User Guide](docs/user_guide.md) â€“ Operation and maintenance manual  
- [Developer Guide](docs/dev_guide.md) â€“ Setup and development instructions

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**â­ Star this repository if you find it useful!**

*Last updated: September 02, 2025*
